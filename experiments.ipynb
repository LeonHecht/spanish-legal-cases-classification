{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to run multiple experiments automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters1 = {\n",
    "    'epochs': 5,\n",
    "    'batch_size': 8,\n",
    "    'weight_decay': 0.01,\n",
    "    'learning_rate': 5e-6,      # lower learning rate\n",
    "    'warmup_steps': 1000,\n",
    "    'metric_for_best_model': \"f1\",\n",
    "    'early_stopping_patience': 4,\n",
    "    'max_length': 1024,\n",
    "    'stride': 512,\n",
    "    'use_weighted_loss': False,\n",
    "    'max_grad_norm': 0,\n",
    "    'gradient_accumulation_steps': 1,\n",
    "    'mixed_precision': True,\n",
    "    'read_datasets': True,\n",
    "    'datasets_read_path': 'datasets/google2',\n",
    "    'save_datasets': False,\n",
    "    'datasets_save_path': None,\n",
    "}\n",
    "\n",
    "hyperparameters2 = {\n",
    "    'epochs': 10,\n",
    "    'batch_size': 8,\n",
    "    'weight_decay': 0.01,\n",
    "    'learning_rate': 5e-6,      # lower learning rate\n",
    "    'warmup_steps': 1000,\n",
    "    'metric_for_best_model': \"f1\",\n",
    "    'early_stopping_patience': 4,\n",
    "    'max_length': 1024,\n",
    "    'stride': 512,\n",
    "    'use_weighted_loss': False,\n",
    "    'max_grad_norm': 0,\n",
    "    'gradient_accumulation_steps': 1,\n",
    "    'mixed_precision': True,\n",
    "    'read_datasets': True,\n",
    "    'datasets_read_path': 'datasets/google2',\n",
    "    'save_datasets': False,\n",
    "    'datasets_save_path': None,\n",
    "}\n",
    "\n",
    "hyperparameters3 = {\n",
    "    'epochs': 5,\n",
    "    'batch_size': 4,\n",
    "    'weight_decay': 0.01,\n",
    "    'learning_rate': 2e-5,\n",
    "    'warmup_steps': 1000,\n",
    "    'metric_for_best_model': \"f1\",\n",
    "    'early_stopping_patience': 4,\n",
    "    'max_length': 1024,\n",
    "    'stride': 512,\n",
    "    'use_weighted_loss': False,\n",
    "    'max_grad_norm': 0,\n",
    "    'gradient_accumulation_steps': 1,\n",
    "    'mixed_precision': False,\n",
    "    'read_datasets': True,\n",
    "    'datasets_read_path': 'datasets/google2',\n",
    "    'save_datasets': False,\n",
    "    'datasets_save_path': None,\n",
    "}\n",
    "\n",
    "hyperparameters4 = {\n",
    "    'epochs': 5,\n",
    "    'batch_size': 4,\n",
    "    'weight_decay': 0.01,\n",
    "    'learning_rate': 2e-5,\n",
    "    'warmup_steps': 1000,\n",
    "    'metric_for_best_model': \"f1\",\n",
    "    'early_stopping_patience': 4,\n",
    "    'max_length': 1024,\n",
    "    'stride': 512,\n",
    "    'use_weighted_loss': True,\n",
    "    'max_grad_norm': 0,\n",
    "    'gradient_accumulation_steps': 1,\n",
    "    'mixed_precision': False,\n",
    "    'read_datasets': True,\n",
    "    'datasets_read_path': 'datasets/google2',\n",
    "    'save_datasets': False,\n",
    "    'datasets_save_path': None,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_checkpoint = 'mrm8488/longformer-base-4096-spanish-finetuned-squad'\n",
    "# model_checkpoint = 'state-spaces/mamba2-130m'\n",
    "model_checkpoint = 'Narrativa/legal-longformer-base-4096-spanish'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus_path='corpus/cleaned_corpus_google_sin_resuelve.csv'\n",
    "# corpus_path='corpus/corpus.csv'\n",
    "# corpus_path4='corpus/corpus_google_min_line_len4_min_par_len2.csv'\n",
    "corpus_path2='corpus/corpus_google_min_line_len2_min_par_len2.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = [\n",
    "    {\n",
    "        'name': 'mixed precision (28)',\n",
    "        'hyperparameters': hyperparameters1,\n",
    "        'model_checkpoint': model_checkpoint,\n",
    "        'corpus_path': corpus_path2\n",
    "    },\n",
    "    {\n",
    "        'name': 'mixed precision with 10 epochs (29)',\n",
    "        'hyperparameters': hyperparameters2,\n",
    "        'model_checkpoint': model_checkpoint,\n",
    "        'corpus_path': corpus_path2\n",
    "    },\n",
    "    {\n",
    "        'name': 'repeating experiment of line 24 (30)',\n",
    "        'hyperparameters': hyperparameters3,\n",
    "        'model_checkpoint': model_checkpoint,\n",
    "        'corpus_path': corpus_path2\n",
    "    },\n",
    "    {\n",
    "        'name': 'repeating experiment of line 24 but with weighted loss (31)',\n",
    "        'hyperparameters': hyperparameters4,\n",
    "        'model_checkpoint': model_checkpoint,\n",
    "        'corpus_path': corpus_path2\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import main\n",
    "\n",
    "for experiment in experiments:\n",
    "    print(\"---------------------------------------------\")\n",
    "    print(f\"\\n\\nRunning experiment {experiment['name']}\")\n",
    "    print(f\"Hyperparameters: {experiment['hyperparameters']}\")\n",
    "    print(f\"Model checkpoint: {experiment['model_checkpoint']}\")\n",
    "    print(f\"Corpus path: {experiment['corpus_path']}\\n\\n\")\n",
    "    print(\"---------------------------------------------\")\n",
    "\n",
    "    main.run_experiment(hyperparameters=experiment['hyperparameters'],\n",
    "                        model_checkpoint=experiment['model_checkpoint'],\n",
    "                        corpus_path=experiment['corpus_path'],\n",
    "                        mamba=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
